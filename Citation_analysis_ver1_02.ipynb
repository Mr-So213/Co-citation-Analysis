{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Citation_analysis_ver1.02.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuS4K8u6lJ-_"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#python-louvain\n",
        "#this module uses louvain method to detect communities in the network\n",
        "import community.community_louvain as community_louvain\n",
        "\n",
        "#STEP1\n",
        "def get_APA7_names(namelist):\n",
        "  names = []\n",
        "  for x in namelist:\n",
        "    Authors = x.split(\";\")\n",
        "    name0 = []\n",
        "    for y in Authors:\n",
        "      Familyname = y.split(\",\")[0]\n",
        "      if \" \" in Familyname:\n",
        "        name0.append(Familyname.replace(\" \", \"\"))\n",
        "      else:\n",
        "        name0.append(Familyname)\n",
        "    names.append(name0)\n",
        "  \n",
        "  APA7_names = []\n",
        "  for i in names:\n",
        "    if len(i) > 2:\n",
        "      APA7_names.append(i[0] + \" et al. \")\n",
        "    elif len(i) == 2:\n",
        "      APA7_names.append(i[0] + \" and \" + i[1] + \" \")\n",
        "    else:\n",
        "      APA7_names.append(i[0] + \" \")\n",
        "  #this will return a list\n",
        "  return APA7_names\n",
        "\n",
        "#STEP2, this combine STEP1 in. \n",
        "def gen_APA7style(Authors, Publication_Year):\n",
        "  APA7style_years = Publication_Year.tolist()\n",
        "  APA7style_names = get_APA7_names(Authors.tolist())\n",
        "  APA7style = []\n",
        "  for x, y in zip(APA7style_names, APA7style_years):\n",
        "    citation = x + \"(\" + str(int(y)) + \")\"\n",
        "    APA7style.append(citation)\n",
        "  \n",
        "  #this will return a list\n",
        "  return APA7style\n",
        "\n",
        "\n",
        "#STEP3 For the References and References to edges\n",
        "#generate a edge list for bipartite graph from \"Cited References\" in WoS excel output \n",
        "\n",
        "\n",
        "def get_References(Cited_References):\n",
        "  References = [i.split(\"; \") for i in Cited_References] # changed in 1.02 , because I found that if I used \";\" as a spliter, the first one will be different with others because of there is a \" \" at the start.\n",
        "  for x in range(len(References)):\n",
        "    References[x] = list(filter(lambda a: a != ' [No title captured]', References[x]))\n",
        "  \n",
        "  #This generate a list of References.\n",
        "  return References\n",
        "\n",
        "\n",
        "def gen_edges(Articles,  References_pdseries):\n",
        "  References = get_References(References_pdseries)\n",
        "  edges = []\n",
        "  for Article, Reference_list in zip(Articles, References):\n",
        "    for Reference in Reference_list:\n",
        "      edges.append([Article, Reference])\n",
        "  \n",
        "  #This generate a list of edges (eg: [[A1,B1], [A2,B2]])\n",
        "  return edges\n",
        "\n",
        "#STEP4\n",
        "#Nodes1 and Nodes2 and Edges for a whole Bipartite Graph\n",
        "#need a list of Articles' name (eg: FirstName et al. (years))\n",
        "def node0_node1_edges(Articles_lst, References_lst):\n",
        "  edges = gen_edges(Articles_lst, References_lst)\n",
        "  nodes_0 = [i[0] for i in edges]\n",
        "  nodes_1 = list(set([i[1] for i in edges]))\n",
        "  return {\"node0\": nodes_0, \"node1\": nodes_1, \"edges\": edges}\n",
        "\n",
        "#STEP5\n",
        "#generate a bipartite graph and only show nodes_0\n",
        "def generate_bipartite_graph(nodes_0, nodes_1, edges):\n",
        "  #generate a bipartite graph\n",
        "  B = nx.Graph()\n",
        "  B.add_nodes_from(nodes_0, bipartite=0)\n",
        "  B.add_nodes_from(nodes_1, bipartite=1)\n",
        "  B.add_edges_from(edges)\n",
        "  #only show nodes_0\n",
        "  G = nx.bipartite.weighted_projected_graph(B, nodes_0)\n",
        "  #this return a nxGraph.object\n",
        "  return G\n",
        "\n",
        "#STEP6\n",
        "#change a bipartite graph to a weighted graph\n",
        "\n",
        "def weighted_graph(Graph, greater):\n",
        "  nxweights = nx.get_edge_attributes(Graph, \"weight\")\n",
        "  contain = dict((k, v) for k, v in nxweights.items() if v >= greater)\n",
        "\n",
        "  #create node, edge , weighted_edge\n",
        "  node_new = list(set([y for x in contain.keys() for y in x]))\n",
        "  edge_new = list(contain.keys())\n",
        "  edge_weights = list(contain.values())\n",
        "  weighted_edge = [[edge[0], edge[1], w] for edge, w in zip(edge_new, edge_weights)]\n",
        "  \n",
        "  #generate the Graph\n",
        "  G_new = nx.Graph()\n",
        "  G_new.add_nodes_from(node_new)\n",
        "  G_new.add_weighted_edges_from(weighted_edge)\n",
        "\n",
        "  #this return a nxGraph.object\n",
        "  return G_new\n",
        "\n",
        "#STEP7\n",
        "#clear the island which only have 2 connecting nodes\n",
        "def clear_island(G):\n",
        "  nodes_picker = [x for x in list(nx.connected_components(G)) if len(x) > 1]\n",
        "  nodes_lst = [y for x in nodes_picker for y in x]\n",
        "  edges_lst_old = list(G.edges)\n",
        "  edges_lst_new = [(i[0], i[1]) for i in edges_lst_old if i[0] and i[1] in nodes_lst]\n",
        "  attrs_old = nx.get_edge_attributes(G, \"weight\")\n",
        "  attrs_new = {edges_lst_new[num]:{\"weight\":attrs_old[edges_lst_new[num]]} for num in range(len(edges_lst_new))}\n",
        "  G_new = nx.Graph()\n",
        "  G_new.add_nodes_from(nodes_lst)\n",
        "  G_new.add_edges_from(edges_lst_new)\n",
        "  nx.set_edge_attributes(G_new, attrs_new)\n",
        "  return G_new\n",
        "\n",
        "#STEP addition\n",
        "#set nodes' attritutes\n",
        "def set_nodes_attrs(G, df):\n",
        "  col = df.columns.to_list()\n",
        "  for i in col:\n",
        "    nx.set_node_attributes(G, pd.Series(df[i], index=df.INDEX).to_dict(), i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a function use all the functions above this to create a nxGraph from WoS excel\n",
        "def generate_FinGraph(df_path, greator=100):\n",
        "  #read and set the df\n",
        "  df = pd.read_excel(df_path)\n",
        "  needed_columns = ['Publication Type','Authors','Article Title', 'Publication Year', 'Source Title','Abstract','Cited References','Times Cited, WoS Core','DOI', 'Keywords Plus']\n",
        "\n",
        "  #organize the df\n",
        "  df = df[needed_columns]\n",
        "  for i in needed_columns:\n",
        "    if i != \"Keywords Plus\":\n",
        "      df.dropna(subset=[i], inplace=True)\n",
        "  \n",
        "  df.reset_index(inplace=True)\n",
        "  \n",
        "  df[\"label\"] = gen_APA7style(df[\"Authors\"], df[\"Publication Year\"])\n",
        "  #set the INDEX\n",
        "  df[\"INDEX\"] = [int(i) for i in range(len(df))]\n",
        "  \n",
        "  \n",
        "  #show how many samples we have\n",
        "  print(\"The number of samples(N): \", len(df))\n",
        "\n",
        "  #Nodes1 and Nodes2 and Edges for a whole Bipartite Graph\n",
        "  N1N2E = node0_node1_edges(df[\"INDEX\"], df[\"Cited References\"]) # this is a dict\n",
        "  \n",
        "  #generate a bipartite graph object\n",
        "  B_Graph = generate_bipartite_graph(N1N2E[\"node0\"], N1N2E[\"node1\"], N1N2E[\"edges\"])#this is a bipartite graph object\n",
        "  \n",
        "  #set node_0's attributes\n",
        "  set_nodes_attrs(B_Graph, df)\n",
        "\n",
        "  #to get the top100 connecting strength\n",
        "  weights = nx.get_edge_attributes(B_Graph, \"weight\")\n",
        "  weights_lst = sorted(list(weights.values()), reverse=True)\n",
        "  greater = weights_lst[greator]\n",
        "  print(\"The connecting strength will be greater than: \", greater)\n",
        "  \n",
        "  #make the graph which we need\n",
        "  Fin_Graph = weighted_graph(B_Graph, greater) #\"greater\" means connecting strength stronger than how many which need to input a int, and it's a \">=\"\n",
        "  \n",
        "  #set the Fin Graph's attrs\n",
        "  df_B_Graph = pd.DataFrame.from_dict(dict(B_Graph.nodes(data=True)), orient='index')\n",
        "  set_nodes_attrs(Fin_Graph, df)\n",
        "\n",
        "  #Fin Graph to df (nodes)\n",
        "  df_Fin_Graph = pd.DataFrame.from_dict(dict(Fin_Graph.nodes(data=True)), orient='index')\n",
        "  \n",
        "  #the Fin of Fin\n",
        "  #clear the isolated nodes, which only connecting two nodes\n",
        "  Fin_Fin_Graph = clear_island(Fin_Graph)\n",
        "\n",
        "  #set the nodes' attributes\n",
        "  set_nodes_attrs(Fin_Fin_Graph, df_Fin_Graph)\n",
        "\n",
        "  #Betweens centralities\n",
        "  bc = nx.betweenness_centrality(Fin_Fin_Graph)\n",
        "  nx.set_node_attributes(Fin_Fin_Graph, bc, \"betweenness\")\n",
        "  \n",
        "  #weight\n",
        "  Fin_weigth = nx.get_edge_attributes(Fin_Graph, \"weight\")\n",
        "  Fin_weigth = {k:{\"weight\":v} for k, v in dict(Fin_weigth).items()}\n",
        "  nx.set_edge_attributes(Fin_Fin_Graph, Fin_weigth)\n",
        "\n",
        "  #set the communities in the nGraph\n",
        "  partition = community_louvain.best_partition(Fin_Fin_Graph)\n",
        "  nx.set_node_attributes(Fin_Fin_Graph, partition, name=\"Community\")\n",
        "\n",
        "  #print a len of nodes and edges\n",
        "  print(\"Nodes data: \" , len(list(Fin_Fin_Graph.nodes(data=True))))\n",
        "  print(\"edges data: \" , len(list(Fin_Fin_Graph.edges(data=True))))\n",
        "\n",
        "  return Fin_Fin_Graph"
      ],
      "metadata": {
        "id": "tfA0bfVbOWSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_before2011 = generate_FinGraph(\"/content/BM_Aplus_Before2011.xlsx\", greator=25)\n",
        "print(\"\\n----------------------------------------------------------\\n\")\n",
        "G_2012to2015 = generate_FinGraph(\"/content/BM_Aplus_2012-2015.xlsx\", greator=28)\n",
        "print(\"\\n----------------------------------------------------------\\n\")\n",
        "G_2016to2019 = generate_FinGraph(\"/content/BM_Aplus_2016-2019.xlsx\", greator=32)\n",
        "print(\"\\n----------------------------------------------------------\\n\")\n",
        "G_2020to2021 = generate_FinGraph(\"/content/BM_Aplus_2020-2021.xlsx\", greator=41)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5blIot0U3jv9",
        "outputId": "0f088c9b-4e7f-4ba6-fc62-a7a9809d17cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples(N):  25\n",
            "The connecting strength will be greater than:  2\n",
            "Nodes data:  15\n",
            "edges data:  36\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n",
            "The number of samples(N):  28\n",
            "The connecting strength will be greater than:  2\n",
            "Nodes data:  22\n",
            "edges data:  45\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n",
            "The number of samples(N):  32\n",
            "The connecting strength will be greater than:  5\n",
            "Nodes data:  13\n",
            "edges data:  31\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n",
            "The number of samples(N):  41\n",
            "The connecting strength will be greater than:  6\n",
            "Nodes data:  25\n",
            "edges data:  54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lst = [pd.DataFrame.from_dict(dict(i.nodes(data=True)), orient='index') for i in [G_before2011, G_2012to2015, G_2016to2019, G_2020to2021]]"
      ],
      "metadata": {
        "id": "qKsEh_2_Y0YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in zip(df_lst, range(len(df_lst))):\n",
        "  x.to_excel(\"BM_Aplus_\" + str(y) + \".xlsx\")"
      ],
      "metadata": {
        "id": "c0JhlTrBZP4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_before2011 = nx.to_pandas_edgelist(G_before2011)\n",
        "edge_2012to2015 = nx.to_pandas_edgelist(G_2012to2015)\n",
        "edge_2016to2019 = nx.to_pandas_edgelist(G_2016to2019)\n",
        "edge_2020to2021 = nx.to_pandas_edgelist(G_2020to2021)\n",
        "\n",
        "edge_before2011.to_excel(\"edge_before2011.xlsx\")\n",
        "edge_2012to2015.to_excel(\"edge_2012to2015.xlsx\")\n",
        "edge_2016to2019.to_excel(\"edge_2016to2019.xlsx\")\n",
        "edge_2020to2021.to_excel(\"edge_2020to2021.xlsx\")"
      ],
      "metadata": {
        "id": "oRFH-w8KUqAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0wM2PWfhCv_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}